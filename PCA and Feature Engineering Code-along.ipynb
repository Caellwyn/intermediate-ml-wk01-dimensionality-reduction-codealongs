{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lmp3JoP2nQzp"
   },
   "source": [
    "# Feature Engineering Code-along Solution\n",
    "\n",
    "In this notebook, we use the following feature engineering strategies:\n",
    "1. scaling\n",
    "2. binning\n",
    "3. log transformation\n",
    "4. PCA\n",
    "\n",
    "The data regards students, features about them, and their scores on an exam.  The orginal data can be found [here on Kaggle](https://www.kaggle.com/code/ramontanoeiro/student-performance)\n",
    "\n",
    "We will use some feature engineering on our data and then try to predict whether students will pass the exam.\n",
    "\n",
    "The minimum passing score is 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:56.990228Z",
     "start_time": "2023-02-03T00:04:56.973308Z"
    },
    "executionInfo": {
     "elapsed": 1171,
     "status": "ok",
     "timestamp": 1668734845596,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "fu6bkefYnK-j"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, ConfusionMatrixDisplay, \\\n",
    "classification_report\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CB3xgtyXzGt"
   },
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:57.005187Z",
     "start_time": "2023-02-03T00:04:56.992223Z"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1668734882041,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "7DVFP_utXyaF"
   },
   "outputs": [],
   "source": [
    "def eval_classification(true, pred, name='Model'):\n",
    "    \n",
    "    \"\"\" Shows classification_report and confusion matrix\n",
    "    for classification model predictions.  Outputs a dataframe of metrics\"\"\"\n",
    "  \n",
    "    print(name, '\\n')\n",
    "    print(classification_report(true, pred))\n",
    "    ConfusionMatrixDisplay.from_predictions(true, pred)\n",
    "    plt.show()\n",
    "\n",
    "    scores = pd.DataFrame()\n",
    "    scores['Model Name'] = [name]\n",
    "    scores['Precision'] = [precision_score(true, pred)]\n",
    "    scores['Recall'] = [recall_score(true, pred)]\n",
    "    scores['F1 Score'] = [f1_score(true, pred)]\n",
    "    scores['Accuracy'] = [accuracy_score(true, pred)]\n",
    "    scores.set_index('Model Name', inplace=True)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def evaluate(model, X_train, y_train, X_test, y_test, name='model'):\n",
    "    \"\"\" Evaluate and time a fit model\n",
    "    returns a dataframe of training and testing metrics and predict times\"\"\"\n",
    "\n",
    "    ## Time the predictions\n",
    "    start = timeit.timeit()\n",
    "    train_pred = model.predict(X_train)\n",
    "    end = timeit.timeit()\n",
    "\n",
    "    train_time = end - start\n",
    "\n",
    "    start = timeit.timeit()\n",
    "    test_pred = model.predict(X_test)\n",
    "    end = timeit.timeit()\n",
    "\n",
    "    test_time = end - start\n",
    "\n",
    "    ## Evaluate the predictions\n",
    "    train_scores = eval_classification(train_pred, y_train, name=name + ' train')\n",
    "    test_scores = eval_classification(test_pred, y_test, name=name + ' test')\n",
    "\n",
    "    train_scores['predict_time'] = train_time\n",
    "    test_scores['predict_time'] = test_time\n",
    "\n",
    "    return pd.concat([train_scores, test_scores])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdIxE4xgNU3m"
   },
   "source": [
    "## Data\n",
    "<br>\n",
    "Today we will use data about used car sales in India from Kaggle.  \n",
    "\n",
    "[Here is the source](https://www.kaggle.com/datasets/saisaathvik/used-cars-dataset-from-cardekhocom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:58.424387Z",
     "start_time": "2023-02-03T00:04:57.006186Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 1318,
     "status": "ok",
     "timestamp": 1668734885834,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "FJb74mnanWAY",
    "outputId": "589733aa-2438-438a-fc20-734e3dc145c1"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "import glob\n",
    "math_files = sorted(glob.glob('Data/Students/*.csv'))\n",
    "math_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_files = sorted(glob.glob('Data/Students/Portugese/*.csv'))\n",
    "port_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:58.424387Z",
     "start_time": "2023-02-03T00:04:57.006186Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 1318,
     "status": "ok",
     "timestamp": 1668734885834,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "FJb74mnanWAY",
    "outputId": "589733aa-2438-438a-fc20-734e3dc145c1"
   },
   "outputs": [],
   "source": [
    "math = pd.concat([pd.read_csv(file) for file in math_files])\n",
    "port = pd.concat([pd.read_csv(file) for file in port_files])\n",
    "\n",
    "df = pd.concat([math, port])\n",
    "\n",
    "df_backup = df.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5Ep8q1T02el"
   },
   "source": [
    "## Explore and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:58.440346Z",
     "start_time": "2023-02-03T00:04:58.426382Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1668734903886,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "jpf0LSXexRPy",
    "outputId": "6ce7af54-b64a-4937-980f-79937349bae1"
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:58.470265Z",
     "start_time": "2023-02-03T00:04:58.456302Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1668734909728,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "VjksV-Zn0gbl",
    "outputId": "ab0684e5-ee57-42c6-9149-34951ccf396a"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:58.500184Z",
     "start_time": "2023-02-03T00:04:58.472258Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1668734928390,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "mPLcxeYt0jMd",
    "outputId": "9d7ba155-8826-474a-8c83-8785805dbaa0"
   },
   "outputs": [],
   "source": [
    "# Check summary statistics\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(exclude='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Regression to Classification: Binning the Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What our stakeholders really want to know is which students will pass and which students will fail the exam.  We also know that a passing score is 12 or higher.  Using this knowledge we can bin the target into passing and failing scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function\n",
    "\n",
    "\n",
    "## Apply the Function\n",
    "\n",
    "## Check Value counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Binary Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace 'yes' and 'no' with 1 and 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the school and subject\n",
    "\n",
    "\n",
    "## drop original columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Outliers: Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check distribution of absences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could just drop the outliers, or we can do a log transform to squick them closer to the other values.  This makes the data more normal without losing any information.\n",
    "\n",
    "We can't get the natural log of 0, so we will just add one to each value to make sure there are no 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Log Transform Absences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "PCA will cause data leakage if we apply it to all rows, since it needs to look at all rows to determine how to transform the data.\n",
    "\n",
    "<font color='red'> We must do the PCA transformation AFTER the split </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data\n",
    "X = df.drop('passed_exam', axis=1)\n",
    "y = df['passed_exam'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessor\n",
    "\n",
    "We will one-hot encode the data, scale it, and then PCA transform it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define transformers\n",
    "scaler = StandardScaler()\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "## Select Columns\n",
    "\n",
    "num_cols = X_train.select_dtypes(include='number').columns\n",
    "cat_cols = X_train.select_dtypes(include='object').columns\n",
    "\n",
    "## define tuples\n",
    "\n",
    "num_tuple = ('Numeric', scaler, num_cols)\n",
    "cat_tuple = ('Nominal', ohe, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the column transformer\n",
    "\n",
    "\n",
    "## Combine the column transformer with a PCA model to transform the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the number of columns with and without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_trans.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "X_train_proc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the explained variance of each principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the explained variance ratio of the pca components\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the engineered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the model\n",
    "knn_eng = KNeighborsClassifier()\n",
    "\n",
    "## Fit the model\n",
    "knn_eng.fit(X_train_proc, y_train)\n",
    "\n",
    "## Evaluate the model\n",
    "scores = evaluate(knn_eng, X_train_proc, y_train, \n",
    "                 X_test_proc, y_test,\n",
    "                 name='KNN Engineered Data')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzLe+q8ocz2qzOeu7MZJ8M",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.616px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
