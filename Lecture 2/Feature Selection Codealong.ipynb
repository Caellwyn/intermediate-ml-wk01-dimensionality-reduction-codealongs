{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50fc6bb9-2edc-4c4a-a513-5dc2d596800a",
   "metadata": {},
   "source": [
    "# Feature Selection Codealong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc2556-28d8-43d9-8299-3568d615606b",
   "metadata": {},
   "source": [
    "In this notebook we will try 3 methods of feature selection:\n",
    "* Filtering by correlation\n",
    "* Selecting via Permutation Importance and SelectFromModel\n",
    "* Applying SequentialFeatureSelector to test many models and find the best combination of features.\n",
    "\n",
    "The data is the engineered data we created in the last lecture.  However, instead of PCA, we will try some feature selection methods.  \n",
    "\n",
    "Once again we will bin the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54d51d-3bd8-4de6-8a14-bd19ab0309df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177fa99-426a-4ac1-996f-9b216be10139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "def classification_metrics(y_true, y_pred, label=\"\",\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False):\n",
    "  # Get the classification report\n",
    "  report = classification_report(y_true, y_pred)\n",
    "  ## Print header and report\n",
    "  header = \"-\"*70\n",
    "  print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "  print(report)\n",
    "  ## CONFUSION MATRICES SUBPLOTS\n",
    "  fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "  # create a confusion matrix  of raw counts\n",
    "  ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=None, cmap='gist_gray', colorbar=colorbar,\n",
    "                ax = axes[0],);\n",
    "  axes[0].set_title(\"Raw Counts\")\n",
    "  # create a confusion matrix with the test data\n",
    "  ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=normalize, cmap=cmap, colorbar=colorbar,\n",
    "                ax = axes[1]);\n",
    "  axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "  # Adjust layout and show figure\n",
    "  fig.tight_layout()\n",
    "  plt.show()\n",
    "  # Return dictionary of classification_report\n",
    "  if output_dict==True:\n",
    "    report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "    return report_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "def evaluate_classification(model, X_train, y_train, X_test, y_test,\n",
    "                         figsize=(6,4), normalize='true', output_dict = False,\n",
    "                            cmap_train='Blues', cmap_test=\"Reds\",colorbar=False):\n",
    "  # Get predictions for training data\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  # Call the helper function to obtain regression metrics for training data\n",
    "  results_train = classification_metrics(y_train, y_train_pred, #verbose = verbose,\n",
    "                                     output_dict=True, figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_train,\n",
    "                                     label='Training Data')\n",
    "  print()\n",
    "  # Get predictions for test data\n",
    "  y_test_pred = model.predict(X_test)\n",
    "  # Call the helper function to obtain regression metrics for test data\n",
    "  results_test = classification_metrics(y_test, y_test_pred, #verbose = verbose,\n",
    "                                  output_dict=True,figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_test,\n",
    "                                    label='Test Data' )\n",
    "  if output_dict == True:\n",
    "    # Store results in a dataframe if ouput_frame is True\n",
    "    results_dict = {'train':results_train,\n",
    "                    'test': results_test}\n",
    "    return results_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061ba63-02f0-4c44-9c3a-a7f3c28d2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = joblib.load('../Lecture 1/Data/engineered_student_data.joblib')\n",
    "loaded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d1d234-836c-4b5a-accb-da06f5c3ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = loaded['X_train']\n",
    "X_test = loaded['X_test']\n",
    "y_train = loaded['y_train']\n",
    "y_test = loaded['y_test']\n",
    "preprocessor = loaded['columntransformer']\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e881a0-d8a5-4dfc-9863-0ce102350726",
   "metadata": {},
   "source": [
    "# Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcfd138-8ad3-4278-b373-dffa4b571c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "X_train_proc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d0ee0-fd8e-47de-87fd-c344233d6f93",
   "metadata": {},
   "source": [
    "# Base Model\n",
    "\n",
    "We will create a base model on all data to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6aed98-dcb0-43ea-991d-31582af59f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and fit the initial model\n",
    "rf_base = RandomForestClassifier(random_state=42)\n",
    "rf_base.fit(X_train_proc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d113dc-423b-4907-9d9c-e376f9d837a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Evaluate the intial model\n",
    "evaluate_classification(rf_base, X_train_proc, y_train, X_test_proc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb2172-521d-487a-8bd3-ac4a1159a75f",
   "metadata": {},
   "source": [
    "# Select Based on: Correlation to Target\n",
    "\n",
    "In this section we will select features based on the correlation of each feature to the target.\n",
    "\n",
    "1. We will join the training features and target.  We will use only training data to avoid peeking at the test data.\n",
    "2. We will determine the correlations between each feature and the target\n",
    "3. We will select only the features whose correlation exceeds a chosen threshold\n",
    "4. We will fit a new model on only the features with higher correlation to the target and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd77c66-62db-48d6-8ed1-8d525a6eda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the features and target\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c2fc8-fb4b-4fce-a7a1-d9f4176f0ae3",
   "metadata": {},
   "source": [
    "We want both strong positive and negatively correlated features, we we will examine the absolute values of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d88e6f6-c08b-4e1b-a379-8e7999f2652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate and the correlations and examine the correlations to the target\n",
    "\n",
    "\n",
    "## Examine the absolute values of the correlations to determine a threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927ecaf-cbfd-4f01-b46f-a1ddeb70abf8",
   "metadata": {},
   "source": [
    "How many features do we want to keep?  The lowest 8 features all have correlations below .03.  We could try that as a threshold.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6259979-1b10-4daa-bb2e-2abc38be5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set a correlation threshold\n",
    "\n",
    "\n",
    "## Create a filter using that threshold\n",
    "\n",
    "\n",
    "## Use the filter to subset the features\n",
    "\n",
    "\n",
    "\n",
    "## Examine the results\n",
    "print(X_train_corr.shape)\n",
    "X_train_corr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ead12c2-0693-4014-87ef-5acac0aef201",
   "metadata": {},
   "source": [
    "## Fit a new model just on the more highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe720620-5777-44ad-9491-6dd8048909a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and fit a model on the higher correlated features\n",
    "rf_corrs = RandomForestClassifier(random_state=42)\n",
    "rf_corrs.fit(X_train_corr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e083e4-bed9-4ac3-8160-113b293e20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Evaluate the correlation model\n",
    "\n",
    "evaluate_classification(rf_corrs, X_train_corr, y_train, X_test_corr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af14bc1-7df6-4260-999f-c01113767c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We reduced the number of features by {X_train_proc.shape[1] - X_train_corr.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12106f80-46a4-46b1-bb7e-8ce5f3316fac",
   "metadata": {},
   "source": [
    "# Select based on: Permutation Importance\n",
    "\n",
    "<font color='red'> You will need to do this on Project 4 Part 1 </font>\n",
    "\n",
    "In this section we will:\n",
    "1. Create and fit an initial model\n",
    "2. Determine feature importances using `permutation_importance()`\n",
    "3. Create a Series using the discovered importances\n",
    "4. Create a filter out of the Series using a chosen threshold\n",
    "5. Use that filter to select which features to keep.\n",
    "6. Fit a new model using the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2975ec-dc17-4dbe-90fc-f609a740ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate feature importances\n",
    "\n",
    "\n",
    "## Create a Series of Feature Importances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa04a76-5bc9-4737-b86c-edc15a6bdad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the importances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f5ee3-31b8-4f57-bbc4-1713bb64c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a filter based on a threshold\n",
    "\n",
    "\n",
    "\n",
    "## Use the filter to select features to keep\n",
    "\n",
    "\n",
    "## Examine the results\n",
    "print(X_train_perm_sel.shape)\n",
    "X_train_perm_sel.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f3199d-1eaa-4b23-a70c-0134c65bd8b8",
   "metadata": {},
   "source": [
    "## Fit a new model just on the more important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025a538-d75b-45d7-a046-62a280341a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and fit a new model on the important features\n",
    "rf_perm_sel = RandomForestClassifier(random_state=42)\n",
    "rf_perm_sel.fit(X_train_perm_sel, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a59e8-9fc1-4fc1-9ec5-571d339ac8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##Evaluate the model using permutation importance selected data\n",
    "evaluate_classification(rf_perm_sel, X_train_perm_sel, y_train, X_test_perm_sel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdfaba5-7ac4-4034-b9a2-134b0e4a6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We reduced the number of features by {X_train_proc.shape[1] - X_train_perm_sel.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b7e853-b751-4974-b285-bb04bc1ab670",
   "metadata": {},
   "source": [
    "# Select Based On: `SequentialFeatureSelection` wrapper class\n",
    "\n",
    "In this section we will use a class that will fit many models with many combinations of features and see which combination is best.  This is simple to code, but can take a very long time!\n",
    "\n",
    "1. Instantiate and fit the SequentialFeatureSelector class.  We will use the base RandomForestClassifier we made earlier for this.\n",
    "2. Extract the features that the class suggests that we keep and use them to filter our data\n",
    "3. Fit and evaluate a new model on just those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea12284-c8b8-4c53-977c-782495d6099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decide on a number of features to keep\n",
    "\n",
    "\n",
    "\n",
    "## Instantiate the feature selector\n",
    "\n",
    "\n",
    "\n",
    "## Fit the feature selector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042b6e6-c15c-4394-b8ad-224b3b23034c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf475c82-15ba-4782-8afa-2dbafcb7f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the features suggested by the selector\n",
    "\n",
    "\n",
    "\n",
    "## Use the filter to subset the features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b7ba3-3e11-4730-ad2d-ce553b4cd317",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instanciate and fit a new model on just the features suggested by the selector\n",
    "rf_selected = RandomForestClassifier(random_state=42)\n",
    "rf_selected.fit(X_train_sel, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3d572-6ef5-484b-a35e-ab5a671baebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Evaluate the model\n",
    "evaluate_classification(rf_selected, X_train_sel, y_train, X_test_sel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83016770-d3c2-4606-8264-5bf9fb92b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We reduced the dimensionality of the feature set by {X_train_proc.shape[1] - X_train_sel.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4e127-293f-4b78-a08a-36bda0178b76",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook we implemented 3 methods for selecting features:\n",
    "\n",
    "1. Selecting based on correlation of features to target\n",
    "2. Selecting based on the permutation importance of each feature\n",
    "3. Selecting based on the suggestions of an Scikit-Learn wrapper class.\n",
    "\n",
    "In all cases we were able to reduce the number of features without significantly hurting the model metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebda956-3648-4812-afd1-bf412ec9b7f5",
   "metadata": {},
   "source": [
    "# Bonus:  SelectFromModel in a Pipeline\n",
    "\n",
    "Since SelectFromModel has a .transform() method, it can be used in a pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d7646b-83ac-44ee-9eb6-273a5aeb3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "## instantiate the selector with a model.\n",
    "selector = SelectFromModel(rf_base)\n",
    "\n",
    "## Put it in a pipeline between a preprocessor and another model\n",
    "sel_pipe = make_pipeline(preprocessor, \n",
    "                         selector, \n",
    "                         RandomForestClassifier(random_state=42))\n",
    "\n",
    "## Fit the pipeline\n",
    "sel_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3554e-d8af-4ff6-a141-d0d06eebff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate the pipeline model\n",
    "evaluate_classification(sel_pipe, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
