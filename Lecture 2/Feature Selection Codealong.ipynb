{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50fc6bb9-2edc-4c4a-a513-5dc2d596800a",
   "metadata": {},
   "source": [
    "# Feature Selection Codealong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc2556-28d8-43d9-8299-3568d615606b",
   "metadata": {},
   "source": [
    "In this notebook we will try 3 methods of feature selection:\n",
    "* Filtering by low multicollinearity\n",
    "* Selecting via Permutation Importance\n",
    "* Using SelectFromModel in a Pipeline\n",
    "* Applying SequentialFeatureSelector to test many models and find the best combination of features.\n",
    "\n",
    "The data is the engineered data we created in the last lecture.  However, instead of PCA, we will try some feature selection methods.  \n",
    "\n",
    "The target Grade, has been binned to create a classification of whose who will pass the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54d51d-3bd8-4de6-8a14-bd19ab0309df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "\n",
    "import joblib\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177fa99-426a-4ac1-996f-9b216be10139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "def classification_metrics(y_true, y_pred, label=\"\",\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False):\n",
    "  # Get the classification report\n",
    "  report = classification_report(y_true, y_pred)\n",
    "  ## Print header and report\n",
    "  header = \"-\"*70\n",
    "  print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "  print(report)\n",
    "  ## CONFUSION MATRICES SUBPLOTS\n",
    "  fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "  # create a confusion matrix  of raw counts\n",
    "  ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=None, cmap='gist_gray', colorbar=colorbar,\n",
    "                ax = axes[0],);\n",
    "  axes[0].set_title(\"Raw Counts\")\n",
    "  # create a confusion matrix with the test data\n",
    "  ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=normalize, cmap=cmap, colorbar=colorbar,\n",
    "                ax = axes[1]);\n",
    "  axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "  # Adjust layout and show figure\n",
    "  fig.tight_layout()\n",
    "  plt.show()\n",
    "  # Return dictionary of classification_report\n",
    "  if output_dict==True:\n",
    "    report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "    return report_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "def evaluate_classification(model, X_train, y_train, X_test, y_test,\n",
    "                         figsize=(6,4), normalize='true', output_dict = False,\n",
    "                            cmap_train='Blues', cmap_test=\"Reds\",colorbar=False):\n",
    "  # Get predictions for training data\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  # Call the helper function to obtain regression metrics for training data\n",
    "  results_train = classification_metrics(y_train, y_train_pred, #verbose = verbose,\n",
    "                                     output_dict=True, figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_train,\n",
    "                                     label='Training Data')\n",
    "  print()\n",
    "  # Get predictions for test data\n",
    "  y_test_pred = model.predict(X_test)\n",
    "  # Call the helper function to obtain regression metrics for test data\n",
    "  results_test = classification_metrics(y_test, y_test_pred, #verbose = verbose,\n",
    "                                  output_dict=True,figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_test,\n",
    "                                    label='Test Data' )\n",
    "  if output_dict == True:\n",
    "    # Store results in a dataframe if ouput_frame is True\n",
    "    results_dict = {'train':results_train,\n",
    "                    'test': results_test}\n",
    "    return results_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061ba63-02f0-4c44-9c3a-a7f3c28d2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = joblib.load('../Lecture 1/Data/engineered_student_data.joblib')\n",
    "loaded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d1d234-836c-4b5a-accb-da06f5c3ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = loaded['X_train']\n",
    "X_test = loaded['X_test']\n",
    "y_train = loaded['y_train']\n",
    "y_test = loaded['y_test']\n",
    "preprocessor = loaded['columntransformer']\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e881a0-d8a5-4dfc-9863-0ce102350726",
   "metadata": {},
   "source": [
    "# Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcfd138-8ad3-4278-b373-dffa4b571c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "X_train_proc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d0ee0-fd8e-47de-87fd-c344233d6f93",
   "metadata": {},
   "source": [
    "# Base Model\n",
    "\n",
    "We will create a base model on all data to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6aed98-dcb0-43ea-991d-31582af59f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and fit the initial model\n",
    "rf_base = RandomForestClassifier(random_state=42)\n",
    "rf_base.fit(X_train_proc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d113dc-423b-4907-9d9c-e376f9d837a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Evaluate the intial model\n",
    "evaluate_classification(rf_base, X_train_proc, y_train, X_test_proc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb2172-521d-487a-8bd3-ac4a1159a75f",
   "metadata": {},
   "source": [
    "# Filter Method: Multi-collinearity\n",
    "\n",
    "In this section we will select features based on the correlation of each feature to the target.\n",
    "\n",
    "1. We will join the training features and target.  We will use only training data to avoid peeking at the test data.\n",
    "2. We will determine the correlations between each feature and the target\n",
    "3. We will select only the features whose correlation exceeds a chosen threshold\n",
    "4. We will fit a new model on only the features with higher correlation to the target and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd77c66-62db-48d6-8ed1-8d525a6eda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Correlations\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(X_train_proc.corr(), cmap='coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c2fc8-fb4b-4fce-a7a1-d9f4176f0ae3",
   "metadata": {},
   "source": [
    "We are seeing come high correlations, especially with one-hot encode columns.  We will set a threshold of .7 to limit multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d88e6f6-c08b-4e1b-a379-8e7999f2652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Some new packages\n",
    "from collinearity import SelectNonCollinear\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927ecaf-cbfd-4f01-b46f-a1ddeb70abf8",
   "metadata": {},
   "source": [
    "`SelectNonCollinear` is a class with will select the features more correlated with the target that are less correlated to other features.\n",
    "\n",
    "f_classif is a metric from sklearn that determines the relationship between features in a classification model.  It uses ANOVA tests to determine this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6259979-1b10-4daa-bb2e-2abc38be5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set a correlation threshold\n",
    "\n",
    "## Instantiate the non-collinear selector\n",
    "\n",
    "\n",
    "## Fit Selector\n",
    "\n",
    "\n",
    "## Use selector to subset the columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ead12c2-0693-4014-87ef-5acac0aef201",
   "metadata": {},
   "source": [
    "## Fit a model with less collinear features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe720620-5777-44ad-9491-6dd8048909a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and fit a model on the higher correlated features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950bbd95-7033-4dc9-9742-81b5bcda4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We reduced dimensionality by {X_train_proc.shape[1] - X_train_non_col.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e083e4-bed9-4ac3-8160-113b293e20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Evaluate the correlation model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af14bc1-7df6-4260-999f-c01113767c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We reduced the number of features by {X_train_proc.shape[1] - X_train_non_col.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12106f80-46a4-46b1-bb7e-8ce5f3316fac",
   "metadata": {},
   "source": [
    "# Embedded Method: Permutation Importance\n",
    "\n",
    "<font color='red'> You will need to do this on Project 4 Part 1 </font>\n",
    "\n",
    "In this section we will:\n",
    "1. Create and fit an initial model\n",
    "2. Determine feature importances using `permutation_importance()`\n",
    "3. Create a Series using the discovered importances\n",
    "4. Create a filter out of the Series using a chosen threshold\n",
    "5. Use that filter to select which features to keep.\n",
    "6. Fit a new model using the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2975ec-dc17-4dbe-90fc-f609a740ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate feature importances\n",
    "\n",
    "\n",
    "## Create a Series of Feature Importances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa04a76-5bc9-4737-b86c-edc15a6bdad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the importances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f5ee3-31b8-4f57-bbc4-1713bb64c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a filter based on a threshold\n",
    "\n",
    "\n",
    "\n",
    "## Use the filter to select features to keep\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f3199d-1eaa-4b23-a70c-0134c65bd8b8",
   "metadata": {},
   "source": [
    "## Fit a new model just on the more important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025a538-d75b-45d7-a046-62a280341a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and fit a new model on only important features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a59e8-9fc1-4fc1-9ec5-571d339ac8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##Evaluate the model using permutation importance selected data\n",
    "evaluate_classification(rf_perm_sel, X_train_perm_sel, y_train, X_test_perm_sel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdfaba5-7ac4-4034-b9a2-134b0e4a6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We reduced the number of features by {X_train_proc.shape[1] - X_train_perm_sel.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b25349f-e46f-4b2e-8756-2c85c2d06918",
   "metadata": {},
   "source": [
    "# Embedded Method: Importance or Coefficients using `SelectFromModel` in a Pipeline\n",
    "\n",
    "* This works with Linear and Tree models only\n",
    "\n",
    "* Since SelectFromModel uses the inherent coefficients or feature importances of a model.  It has a .transform() method, it can be used in a pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04868f-c7e3-4529-a02a-2cfec4841a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## instantiate the selector with a model.\n",
    "\n",
    "\n",
    "## Put it in a pipeline between a preprocessor and another model\n",
    "\n",
    "\n",
    "\n",
    "## Fit the pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22513dcf-66a2-45ef-a8c5-d568878a7a7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Evaluate the pipeline model\n",
    "evaluate_classification(sel_pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b7e853-b751-4974-b285-bb04bc1ab670",
   "metadata": {},
   "source": [
    "# Wrapper Method: `SequentialFeatureSelection` Class\n",
    "\n",
    "In this section we will use a class that will fit many models with many combinations of features and see which combination is best.  This is simple to code, but can take a very long time!\n",
    "\n",
    "1. Instantiate and fit the SequentialFeatureSelector class.  We will use the base RandomForestClassifier we made earlier for this.\n",
    "2. Extract the features that the class suggests that we keep and use them to filter our data\n",
    "3. Fit and evaluate a new model on just those features.\n",
    "\n",
    "\n",
    "**In all cases, the general flow is to identify the features to keep, subset the dataframe, then fit and evaluate a model on those features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea12284-c8b8-4c53-977c-782495d6099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decide on a number of features to keep\n",
    "\n",
    "\n",
    "## Instantiate the feature selector\n",
    "\n",
    "\n",
    "\n",
    "## Fit the feature selector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf475c82-15ba-4782-8afa-2dbafcb7f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the features suggested by the selector\n",
    "\n",
    "\n",
    "## Use the filter to subset the features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b7ba3-3e11-4730-ad2d-ce553b4cd317",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instanciate and fit a new model on just the features suggested by the selector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3d572-6ef5-484b-a35e-ab5a671baebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Evaluate the model\n",
    "evaluate_classification(rf_selected, X_train_sel, y_train, X_test_sel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83016770-d3c2-4606-8264-5bf9fb92b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We reduced the dimensionality of the feature set by {X_train_proc.shape[1] - X_train_sel.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4e127-293f-4b78-a08a-36bda0178b76",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook we implemented 3 methods for selecting features:\n",
    "\n",
    "1. Selecting based on multicollinearity of features\n",
    "2. Selecting based on the permutation importance of each feature\n",
    "3. Selecting based on the suggestions of an Scikit-Learn wrapper class.\n",
    "\n",
    "In all cases we were able to reduce the number of features without significantly hurting the model metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
