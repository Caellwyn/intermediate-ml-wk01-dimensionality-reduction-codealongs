{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lmp3JoP2nQzp"
   },
   "source": [
    "# Feature Engineering Code-along\n",
    "\n",
    "In this notebook, we use the following feature engineering strategies:\n",
    "1. scaling\n",
    "2. binning\n",
    "3. log transformation\n",
    "4. PCA\n",
    "\n",
    "The data regards students, features about them, and their scores on an exam.  The orginal data can be found [here on Kaggle](https://www.kaggle.com/datasets/uciml/student-alcohol-consumption)\n",
    "\n",
    "We will use some feature engineering on our data and then try to predict whether students will pass the exam.\n",
    "\n",
    "The minimum passing score is 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dictionary\n",
    "\n",
    "1. school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n",
    "2. sex - student's sex (binary: 'F' - female or 'M' - male)\n",
    "3. age - student's age (numeric: from 15 to 22)\n",
    "4. address - student's home address type (binary: 'U' - urban or 'R' - rural)\n",
    "5. famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n",
    "6. Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\n",
    "7. Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "8. Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "9. Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "10. Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "11. reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n",
    "12. guardian - student's guardian (nominal: 'mother', 'father' or 'other')\n",
    "13. traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "14. studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "15. failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "16. schoolsup - extra educational support (binary: yes or no)\n",
    "17. famsup - family educational support (binary: yes or no)\n",
    "18. paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "19. activities - extra-curricular activities (binary: yes or no)\n",
    "20. nursery - attended nursery school (binary: yes or no)\n",
    "21. higher - wants to take higher education (binary: yes or no)\n",
    "22. internet - Internet access at home (binary: yes or no)\n",
    "23. romantic - with a romantic relationship (binary: yes or no)\n",
    "24. famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "25. freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "26. goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "27. Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "28. Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "29. health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "30. absences - number of school absences (numeric: from 0 to 93)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:56.990228Z",
     "start_time": "2023-02-03T00:04:56.973308Z"
    },
    "executionInfo": {
     "elapsed": 1171,
     "status": "ok",
     "timestamp": 1668734845596,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "fu6bkefYnK-j"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, ConfusionMatrixDisplay, \\\n",
    "classification_report\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CB3xgtyXzGt"
   },
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:57.005187Z",
     "start_time": "2023-02-03T00:04:56.992223Z"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1668734882041,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "7DVFP_utXyaF"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "def classification_metrics(y_true, y_pred, label=\"\",\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False):\n",
    "  # Get the classification report\n",
    "  report = classification_report(y_true, y_pred)\n",
    "  ## Print header and report\n",
    "  header = \"-\"*70\n",
    "  print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "  print(report)\n",
    "  ## CONFUSION MATRICES SUBPLOTS\n",
    "  fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "  # create a confusion matrix  of raw counts\n",
    "  ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=None, cmap='gist_gray', colorbar=colorbar,\n",
    "                ax = axes[0],);\n",
    "  axes[0].set_title(\"Raw Counts\")\n",
    "  # create a confusion matrix with the test data\n",
    "  ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=normalize, cmap=cmap, colorbar=colorbar,\n",
    "                ax = axes[1]);\n",
    "  axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "  # Adjust layout and show figure\n",
    "  fig.tight_layout()\n",
    "  plt.show()\n",
    "  # Return dictionary of classification_report\n",
    "  if output_dict==True:\n",
    "    report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "    return report_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "def evaluate_classification(model, X_train, y_train, X_test, y_test,\n",
    "                         figsize=(6,4), normalize='true', output_dict = False,\n",
    "                            cmap_train='Blues', cmap_test=\"Reds\",colorbar=False):\n",
    "  # Get predictions for training data\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  # Call the helper function to obtain regression metrics for training data\n",
    "  results_train = classification_metrics(y_train, y_train_pred, #verbose = verbose,\n",
    "                                     output_dict=True, figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_train,\n",
    "                                     label='Training Data')\n",
    "  print()\n",
    "  # Get predictions for test data\n",
    "  y_test_pred = model.predict(X_test)\n",
    "  # Call the helper function to obtain regression metrics for test data\n",
    "  results_test = classification_metrics(y_test, y_test_pred, #verbose = verbose,\n",
    "                                  output_dict=True,figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_test,\n",
    "                                    label='Test Data' )\n",
    "  if output_dict == True:\n",
    "    # Store results in a dataframe if ouput_frame is True\n",
    "    results_dict = {'train':results_train,\n",
    "                    'test': results_test}\n",
    "    return results_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdIxE4xgNU3m"
   },
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:58.424387Z",
     "start_time": "2023-02-03T00:04:57.006186Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 1318,
     "status": "ok",
     "timestamp": 1668734885834,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "FJb74mnanWAY",
    "outputId": "589733aa-2438-438a-fc20-734e3dc145c1"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "import glob\n",
    "math_files = sorted(glob.glob('Data/Students/*.csv'))\n",
    "math_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_files = sorted(glob.glob('Data/Students/Portugese/*.csv'))\n",
    "port_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:58.424387Z",
     "start_time": "2023-02-03T00:04:57.006186Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 1318,
     "status": "ok",
     "timestamp": 1668734885834,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "FJb74mnanWAY",
    "outputId": "589733aa-2438-438a-fc20-734e3dc145c1"
   },
   "outputs": [],
   "source": [
    "math = pd.concat([pd.read_csv(file) for file in math_files])\n",
    "port = pd.concat([pd.read_csv(file) for file in port_files])\n",
    "\n",
    "df = pd.concat([math, port])\n",
    "\n",
    "df_backup = df.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5Ep8q1T02el"
   },
   "source": [
    "## Explore and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:58.440346Z",
     "start_time": "2023-02-03T00:04:58.426382Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1668734903886,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "jpf0LSXexRPy",
    "outputId": "6ce7af54-b64a-4937-980f-79937349bae1"
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:58.470265Z",
     "start_time": "2023-02-03T00:04:58.456302Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1668734909728,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "VjksV-Zn0gbl",
    "outputId": "ab0684e5-ee57-42c6-9149-34951ccf396a"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T00:04:58.500184Z",
     "start_time": "2023-02-03T00:04:58.472258Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1668734928390,
     "user": {
      "displayName": "Josh Johnson",
      "userId": "08606005069848925988"
     },
     "user_tz": 480
    },
    "id": "mPLcxeYt0jMd",
    "outputId": "9d7ba155-8826-474a-8c83-8785805dbaa0"
   },
   "outputs": [],
   "source": [
    "# Check summary statistics\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(exclude='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Regression to Classification: Binning the Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What our stakeholders really want to know is which students will pass and which students will fail the exam.  We also know that a passing score is 12 or higher.  Using this knowledge we can bin the target into passing and failing scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function\n",
    "\n",
    "\n",
    "## Apply the Function\n",
    "\n",
    "## Check Value counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Features\n",
    "\n",
    "Walc is weekend alcohol consumption and Dalc is weekday alcohol consumption.  We can combine these into one column, overall alcohol consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add together the different alcohol consumption columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Binary Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace 'yes' and 'no' with 1 and 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the school and subject\n",
    "\n",
    "\n",
    "## drop original columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Outliers: Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check distribution of absences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could just drop the outliers, or we can do a log transform to squick them closer to the other values.  This makes the data more normal without losing any information.\n",
    "\n",
    "We can't get the natural log of 0, so we will just add one to each value to make sure there are no 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Log Transform Absences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "PCA will cause data leakage if we apply it to all rows, since it needs to look at all rows to determine how to transform the data.\n",
    "\n",
    "<font color='red'> We must do the PCA transformation AFTER the split </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data\n",
    "X = df.drop('passed_exam', axis=1)\n",
    "y = df['passed_exam'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessor\n",
    "\n",
    "We will one-hot encode the data, scale it, and then PCA transform it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define transformers\n",
    "scaler = StandardScaler()\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "## Select Columns\n",
    "\n",
    "num_cols = X_train.select_dtypes(include='number').columns\n",
    "cat_cols = X_train.select_dtypes(include='object').columns\n",
    "\n",
    "## define tuples\n",
    "\n",
    "num_tuple = ('Numeric', scaler, num_cols)\n",
    "cat_tuple = ('Nominal', ohe, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the column transformer\n",
    "\n",
    "\n",
    "## Combine the column transformer with a PCA model to transform the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the number of columns with and without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_trans.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "X_train_proc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the explained variance of each principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the explained variance ratio of the pca components\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the engineered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the model\n",
    "knn_eng = KNeighborsClassifier()\n",
    "\n",
    "## Fit the model\n",
    "knn_eng.fit(X_train_proc, y_train)\n",
    "\n",
    "## Evaluate the model\n",
    "evaluate_classification(knn_eng, X_train_proc, y_train, \n",
    "                 X_test_proc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzLe+q8ocz2qzOeu7MZJ8M",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.616px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
